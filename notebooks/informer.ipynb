{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction_length(이 경우 48시간): 정보 제공자의 디코더가 예측을 학습할 기간입니다\n",
    "- context_length: context_length가 지정되지 않은 경우, 모델은 context_length(인코더의 입력)를 prediction_length와 동일하게 설정합니다\n",
    "- lags for a given frequency: 이는 효율적인 \"되돌아보기\" 메커니즘을 지정하며, 과거 값과 현재 값을 추가 기능으로 연결합니다(예: 일일 빈도의 경우 [1, 7, 30, ...] 또는 분 데이터의 경우 [1, 30, 60, 60*24, ...] 등을 고려할 수 있습니다)\n",
    "- the number of time features: 이 경우에는 시간, 요일, ... 및 연령 기능을 추가할 것이므로 5개가 됩니다(아래 참조)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import timedelta\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model을 import\n",
    "from transformers import InformerModel\n",
    "from gluonts.time_feature import get_lags_for_frequency, time_features_from_frequency_str\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler():\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean(0)\n",
    "        self.std = data.std(0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data * std) + mean\n",
    "\n",
    "# 시간 특징을 freq에 따라 추출\n",
    "def time_features(dates, freq='1s'):\n",
    "    timestamp_as_index = pd.DatetimeIndex(dates)\n",
    "    time_features = time_features_from_frequency_str(freq)\n",
    "    additional_features = [\n",
    "        (time_feature.__name__, time_feature(timestamp_as_index))\n",
    "        for time_feature in time_features\n",
    "    ]\n",
    "        \n",
    "    time_features = pd.DataFrame(dict(additional_features))  \n",
    "    \n",
    "    return time_features.values\n",
    "\n",
    "# 한번의 batch를 실행하는 코드\n",
    "def _process_one_batch(batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "    dec_inp = torch.zeros([batch_y.shape[0], pred_len, batch_y.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:label_len,:], dec_inp], dim=1).float().to(device)\n",
    "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    batch_y = batch_y[:,-pred_len:,0:].to(device)\n",
    "    return outputs, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Pred(Dataset):\n",
    "    def __init__(self, dataframe, size=None, scale=True):\n",
    "        self.fisrt_dt = None\n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2]\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        self.scale = scale\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = self.dataframe\n",
    "        # df_raw[\"STCK_CNTG_HOUR\"] = pd.to_datetime(df_raw[\"STCK_CNTG_HOUR\"])\n",
    "        df_raw[\"AMOUNT\"] = df_raw[\"STCK_PRPR\"].values * df_raw[\"CNTG_VOL\"].values\n",
    "        delta = df_raw[\"STCK_CNTG_HOUR\"].iloc[1] - df_raw[\"STCK_CNTG_HOUR\"].iloc[0]\n",
    "        self.first_time = df_raw[\"STCK_CNTG_HOUR\"].values[0]\n",
    "        \n",
    "        if delta>=timedelta(hours=1):\n",
    "            self.freq='h'\n",
    "        else:\n",
    "            self.freq='t'\n",
    "\n",
    "        border1 = 0\n",
    "        border2 = len(df_raw)\n",
    "        input_columns = list(df_raw.columns.difference([\"MKSC_SHRN_ISCD\", \"day_of_year\", \"STCK_CNTG_HOUR\", \"STCK_PRPR\", \"CCLD_DVSN\"]))\n",
    "        df_data = df_raw[input_columns]\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        \n",
    "        df_stamp = df_raw[\"STCK_CNTG_HOUR\"]\n",
    "\n",
    "        data_stamp = time_features(df_stamp)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "    #######################################################04:15 취침 (수정 필요) ####################################################\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = self.first_time + pd.Timedelta(seconds=index)\n",
    "        s_end = s_begin + pd.Timedelta(seconds=self.seq_len) # self.seq_len # pd.Timedelta(seconds=self.seq_len)\n",
    "        \n",
    "        r_begin = s_end - pd.Timedelta(seconds=self.label_len) # pd.Timedelta(seconds=self.label_len)\n",
    "        r_end = r_begin + pd.Timedelta(seconds=self.label_len) + pd.Timedelta(seconds=self.pred_len) # pd.Timedelta(seconds=self.label_len + self.pred_len)\n",
    "        print(self.data_x)\n",
    " \n",
    "        seq_x = self.data_x.loc[s_begin:s_end, \"STCK_CNTG_HOUR\"]\n",
    "        seq_y = self.data_y.loc[r_begin:r_end, \"STCK_CNTG_HOUR\"]\n",
    "        seq_x_mark = self.data_stamp.loc[s_begin:s_end, \"STCK_CNTG_HOUR\"]\n",
    "        seq_y_mark = self.data_stamp.loc[r_begin:r_end, \"STCK_CNTG_HOUR\"]\n",
    "        \n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "####################################################################################################################################\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len- self.pred_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from glob import glob\n",
    "import os, sys\n",
    "\n",
    "paths = sorted(glob(os.path.join(os.path.dirname(os.path.abspath(os.getcwd())),\"data/raw/*.parquet\")))\n",
    "dataset = Dataset_Pred(pd.read_parquet(paths[0]), scale=True, size = (60, 30, 30))\n",
    "dl = DataLoader(Dataset_Pred(pd.read_parquet(paths[0]), size=[24, 24, 24]), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06141017 -0.06248157]\n",
      " [-0.06141017 -0.06248157]\n",
      " [ 0.02997654  0.02685745]\n",
      " ...\n",
      " [-0.03694056 -0.03475567]\n",
      " [-0.06179934 -0.06248157]\n",
      " [-0.05351308 -0.05323961]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseq_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_y_mark\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\choiseokgyu\\Fin\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\choiseokgyu\\Fin\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\choiseokgyu\\Fin\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\choiseokgyu\\Fin\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[124], line 52\u001b[0m, in \u001b[0;36mDataset_Pred.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     49\u001b[0m r_end \u001b[38;5;241m=\u001b[39m r_begin \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_len) \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len) \u001b[38;5;66;03m# pd.Timedelta(seconds=self.label_len + self.pred_len)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_x)\n\u001b[1;32m---> 52\u001b[0m seq_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m[s_begin:s_end, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTCK_CNTG_HOUR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     53\u001b[0m seq_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y\u001b[38;5;241m.\u001b[39mloc[r_begin:r_end, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTCK_CNTG_HOUR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     54\u001b[0m seq_x_mark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_stamp\u001b[38;5;241m.\u001b[39mloc[s_begin:s_end, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTCK_CNTG_HOUR\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "for seq_x, seq_y, seq_x_mark, seq_y_mark in dl:\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, sys\n",
    "# sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "paths = sorted(glob(os.path.join(os.path.dirname(os.path.abspath(os.getcwd())),\"data/raw/*.parquet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKSC_SHRN_ISCD</th>\n",
       "      <th>STCK_CNTG_HOUR</th>\n",
       "      <th>STCK_PRPR</th>\n",
       "      <th>CNTG_VOL</th>\n",
       "      <th>CCLD_DVSN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-09-11 08:30:00</td>\n",
       "      <td>583000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-09-11 08:30:00</td>\n",
       "      <td>583000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-09-11 08:30:00</td>\n",
       "      <td>583000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-09-11 08:30:00</td>\n",
       "      <td>583000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-09-11 08:30:00</td>\n",
       "      <td>583000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714727</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-10-04 15:56:55</td>\n",
       "      <td>511000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714728</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-10-04 15:57:42</td>\n",
       "      <td>511000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714729</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-10-04 15:57:55</td>\n",
       "      <td>511000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714730</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-10-04 15:58:39</td>\n",
       "      <td>511000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714731</th>\n",
       "      <td>005490</td>\n",
       "      <td>2023-10-04 15:58:46</td>\n",
       "      <td>511000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714732 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MKSC_SHRN_ISCD      STCK_CNTG_HOUR  STCK_PRPR  CNTG_VOL  CCLD_DVSN\n",
       "0              005490 2023-09-11 08:30:00   583000.0       1.0        3.0\n",
       "1              005490 2023-09-11 08:30:00   583000.0       1.0        3.0\n",
       "2              005490 2023-09-11 08:30:00   583000.0      30.0        3.0\n",
       "3              005490 2023-09-11 08:30:00   583000.0       3.0        3.0\n",
       "4              005490 2023-09-11 08:30:00   583000.0       3.0        3.0\n",
       "...               ...                 ...        ...       ...        ...\n",
       "714727         005490 2023-10-04 15:56:55   511000.0       5.0        5.0\n",
       "714728         005490 2023-10-04 15:57:42   511000.0       3.0        5.0\n",
       "714729         005490 2023-10-04 15:57:55   511000.0      10.0        5.0\n",
       "714730         005490 2023-10-04 15:58:39   511000.0       1.0        5.0\n",
       "714731         005490 2023-10-04 15:58:46   511000.0       4.0        5.0\n",
       "\n",
       "[714732 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "dataset = DS(data_paths=paths[:2], window_size=(3, 0), target_size=(1, 0))\n",
    "# dataset\n",
    "\n",
    "progress = tqdm(DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_func(True)), total=len(dataset))\n",
    "for idx, boxcox_lambda, x, y in progress:\n",
    "    progress.n = idx\n",
    "    progress.refresh()\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
