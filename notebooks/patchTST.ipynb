{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/patchtsmixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import random\n",
    "\n",
    "# Third Party\n",
    "from transformers import (\n",
    "    EarlyStoppingCallback,\n",
    "    PatchTSMixerConfig,\n",
    "    PatchTSMixerForPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# First Party\n",
    "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
    "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
    "from tsfm_public.toolkit.util import select_by_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Load and ready\n",
    "\n",
    "- dataset_path: 로컬 .csv 파일의 경로 또는 관심 있는 데이터의 csv 파일에 대한 웹 주소입니다. 데이터는 판다로 로드되므로 pd.read_csv에서 지원하는 것은 무엇이든 지원됩니다: (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "- timestamp_column: 타임스탬프 정보가 포함된 열 이름, 해당 열이 없는 경우 None을 사용합니다.\n",
    "- id_columns: 서로 다른 시계열의 ID를 지정하는 열 이름 목록입니다. ID 열이 없는 경우 []를 사용합니다.\n",
    "- forecast_columns: 모델링할 열 목록입니다.\n",
    "- context_length: 모델에 입력으로 사용되는 과거 데이터의 양입니다. 입력 데이터 프레임에서 context_length와 같은 길이를 가진 입력 시계열 데이터의 윈도우가 추출됩니다. 다중 시계열 데이터 집합의 경우, 컨텍스트 윈도우는 단일 시계열(즉, 단일 ID) 내에 포함되도록 만들어집니다.\n",
    "- forecast_horizon: 앞으로 예측할 타임스탬프의 수입니다.\n",
    "- train_start_index, train_end_index: 학습 데이터를 나타내는 로드된 데이터의 시작 및 종료 인덱스입니다.\n",
    "- valid_start_index, valid_end_index: 유효성 검사 데이터를 나타내는 로드된 데이터의 시작 및 종료 인덱스입니다.\n",
    "- test_start_index, test_end_index: 로드된 데이터에서 테스트 데이터를 나타내는 시작 및 종료 인덱스입니다.\n",
    "- num_workers: PyTorch 데이터로더의 CPU 워커 수입니다.\n",
    "- batch_size: 배치 크기. 데이터는 먼저 Pandas 데이터 프레임에 로드되고 훈련, 검증 및 테스트 부분으로 나뉩니다. 그런 다음 Pandas 데이터 프레임은 학습에 필요한 적절한 PyTorch 데이터 세트로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# Download ECL data from https://github.com/zhouhaoyi/Informer2020\n",
    "dataset_path = glob(os.path.join(os.path.abspath(os.path.pardir), \"data\", \"raw\", \"*.parquet\"))\n",
    "timestamp_column = \"STCK_CNTG_HOUR\"\n",
    "id_columns = []\n",
    "\n",
    "context_length = 512 # 512\n",
    "forecast_horizon = 96 # 96\n",
    "num_workers = 16  # Reduce this if you have low number of CPU cores\n",
    "batch_size = 2  # Adjust according to GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AMOUNT', 'CCLD_DVSN', 'CNTG_VOL', 'STCK_PRPR']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(\n",
    "    dataset_path[11],\n",
    "    # parse_dates=[timestamp_column],\n",
    ")\n",
    "######################\n",
    "from gluonts.time_feature import get_lags_for_frequency, time_features_from_frequency_str\n",
    "\n",
    "data[\"AMOUNT\"] = data[\"STCK_PRPR\"] * data[\"CNTG_VOL\"]\n",
    "data[\"target\"] = data[\"STCK_PRPR\"].pct_change(periods=context_length).fillna(0.)\n",
    "\n",
    "# freq = \"1s\"\n",
    "# lags_sequence = get_lags_for_frequency(freq)\n",
    "# time_features = time_features_from_frequency_str(freq)\n",
    "\n",
    "# timestamp_as_index = pd.DatetimeIndex(data[timestamp_column])\n",
    "# additional_features = [\n",
    "#     (time_feature.__name__, time_feature(timestamp_as_index))\n",
    "#     for time_feature in time_features\n",
    "# ]\n",
    "# data = pd.concat([data, pd.DataFrame(dict(additional_features))], axis=1)\n",
    "\n",
    "######################\n",
    "\n",
    "forecast_columns = list(data.columns.difference([timestamp_column, \"MKSC_SHRN_ISCD\", \"target\", \"day_of_year\"]))\n",
    "forecast_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get split\n",
    "num_train = int(len(data) * 0.7)\n",
    "num_test = int(len(data) * 0.2)\n",
    "num_valid = len(data) - num_train - num_test\n",
    "border1s = [\n",
    "    0,\n",
    "    num_train - context_length,\n",
    "    len(data) - num_test - context_length,\n",
    "]\n",
    "border2s = [num_train, num_train + num_valid, len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Border 1s : [0, 42636, 48801]\n",
      "Border 2s : [43148, 49313, 61641]\n"
     ]
    }
   ],
   "source": [
    "print(\"Border 1s :\",border1s)\n",
    "print(\"Border 2s :\",border2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_index = border1s[0]  # None indicates beginning of dataset\n",
    "train_end_index = border2s[0]\n",
    "\n",
    "# Validation의 시작을 컨텍스트 길이만큼 뒤로 이동하여 첫 번째 validation 타임스탬프가 Train 데이터 바로 다음에 오도록 합니다.\n",
    "valid_start_index = border1s[1]\n",
    "valid_end_index = border2s[1]\n",
    "\n",
    "test_start_index = border1s[2]\n",
    "test_end_index = border2s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start Index : 0\n",
      "Train End Index : 43148\n",
      "Validation Start Index : 42636\n",
      "Validation End Index : 49313\n",
      "Test Start Index : 48801\n",
      "Test End Index : 61641\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Start Index :\", train_start_index)\n",
    "print(\"Train End Index :\", train_end_index)\n",
    "\n",
    "print(\"Validation Start Index :\", valid_start_index)\n",
    "print(\"Validation End Index :\", valid_end_index)\n",
    "\n",
    "print(\"Test Start Index :\", test_start_index)\n",
    "print(\"Test End Index :\", test_end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesPreprocessor {\n",
       "  \"context_length\": 512,\n",
       "  \"feature_extractor_type\": \"TimeSeriesPreprocessor\",\n",
       "  \"id_columns\": [],\n",
       "  \"input_columns\": [\n",
       "    \"AMOUNT\",\n",
       "    \"CCLD_DVSN\",\n",
       "    \"CNTG_VOL\",\n",
       "    \"STCK_PRPR\"\n",
       "  ],\n",
       "  \"output_columns\": [\n",
       "    \"AMOUNT\",\n",
       "    \"CCLD_DVSN\",\n",
       "    \"CNTG_VOL\",\n",
       "    \"STCK_PRPR\"\n",
       "  ],\n",
       "  \"prediction_length\": 96,\n",
       "  \"processor_class\": \"TimeSeriesPreprocessor\",\n",
       "  \"scale_outputs\": false,\n",
       "  \"scaler_dict\": {},\n",
       "  \"scaling\": false,\n",
       "  \"time_series_task\": \"forecasting\",\n",
       "  \"timestamp_column\": \"STCK_CNTG_HOUR\"\n",
       "}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=train_start_index,\n",
    "    end_index=train_end_index,\n",
    ")\n",
    "valid_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=valid_start_index,\n",
    "    end_index=valid_end_index,\n",
    ")\n",
    "test_data = select_by_index(\n",
    "    data,\n",
    "    id_columns=id_columns,\n",
    "    start_index=test_start_index,\n",
    "    end_index=test_end_index,\n",
    ")\n",
    "\n",
    "time_series_processor = TimeSeriesPreprocessor(\n",
    "    context_length=context_length,\n",
    "    timestamp_column=timestamp_column,\n",
    "    id_columns=id_columns,\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    prediction_length=forecast_horizon,\n",
    "    scaling=False,\n",
    "    scale_outputs=False\n",
    ")\n",
    "\n",
    "time_series_processor.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ForecastDFDataset(\n",
    "    time_series_processor.preprocess(train_data),\n",
    "    id_columns=id_columns,\n",
    "    timestamp_column=\"STCK_CNTG_HOUR\",\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "valid_dataset = ForecastDFDataset(\n",
    "    time_series_processor.preprocess(valid_data),\n",
    "    id_columns=id_columns,\n",
    "    timestamp_column=\"STCK_CNTG_HOUR\",\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    ")\n",
    "test_dataset = ForecastDFDataset(\n",
    "    time_series_processor.preprocess(test_data),\n",
    "    id_columns=id_columns,\n",
    "    timestamp_column=\"STCK_CNTG_HOUR\",\n",
    "    input_columns=forecast_columns,\n",
    "    output_columns=forecast_columns,\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_values : torch.Size([512, 4])\n",
      "future_values : torch.Size([96, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"past_values :\",train_dataset[0][\"past_values\"].shape)\n",
    "print(\"future_values :\",train_dataset[0][\"future_values\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'past_values': tensor([[1.5800e+03, 1.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [7.9000e+04, 1.0000e+00, 5.0000e+01, 1.5800e+03],\n",
       "         [1.5800e+03, 1.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         ...,\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03]]),\n",
       " 'future_values': tensor([[1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.6104e+06, 5.0000e+00, 1.0160e+03, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.1095e+04, 5.0000e+00, 7.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [9.5100e+05, 5.0000e+00, 6.0000e+02, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [1.0870e+06, 5.0000e+00, 6.8800e+02, 1.5800e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.7490e+04, 1.0000e+00, 1.1000e+01, 1.5900e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [3.1700e+03, 1.0000e+00, 2.0000e+00, 1.5850e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [2.2190e+04, 1.0000e+00, 1.4000e+01, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+04, 1.0000e+00, 1.0000e+01, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [3.1900e+03, 1.0000e+00, 2.0000e+00, 1.5950e+03],\n",
       "         [1.5950e+03, 1.0000e+00, 1.0000e+00, 1.5950e+03],\n",
       "         [1.5900e+03, 5.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [2.8636e+06, 1.0000e+00, 1.8010e+03, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1323e+05, 5.0000e+00, 1.9700e+02, 1.5900e+03],\n",
       "         [1.5950e+03, 1.0000e+00, 1.0000e+00, 1.5950e+03],\n",
       "         [2.3141e+05, 5.0000e+00, 1.4600e+02, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5485e+06, 5.0000e+00, 9.7700e+02, 1.5850e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5900e+03, 5.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [3.1800e+03, 1.0000e+00, 2.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [4.6916e+05, 1.0000e+00, 2.9600e+02, 1.5850e+03],\n",
       "         [1.5800e+03, 5.0000e+00, 1.0000e+00, 1.5800e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [3.1700e+03, 1.0000e+00, 2.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 1.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5950e+03, 1.0000e+00, 1.0000e+00, 1.5950e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [2.1942e+05, 1.0000e+00, 1.3800e+02, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 5.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5950e+03, 1.0000e+00, 1.0000e+00, 1.5950e+03],\n",
       "         [1.4310e+04, 5.0000e+00, 9.0000e+00, 1.5900e+03],\n",
       "         [1.5950e+03, 1.0000e+00, 1.0000e+00, 1.5950e+03],\n",
       "         [1.5900e+03, 5.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 5.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5850e+03, 5.0000e+00, 1.0000e+00, 1.5850e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03],\n",
       "         [1.5900e+03, 1.0000e+00, 1.0000e+00, 1.5900e+03]]),\n",
       " 'timestamp': numpy.datetime64('2022-02-23T09:02:35.000000000')}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the PatchTSMixer model\n",
    "- num_input_channels: 시계열 데이터의 입력 채널(또는 차원) 수입니다. 이 값은 예측 열의 수로 자동 설정됩니다.\n",
    "- context_length: 위에서 설명한 대로 모델에 입력으로 사용된 과거 데이터의 양입니다.\n",
    "- prediction_length: 위에서 설명한 예측 기간과 동일합니다.\n",
    "- patch_length: PatchTSMixer 모델의 패치 길이입니다. context_length를 균등하게 나누는 값을 선택하는 것이 좋습니다.\n",
    "- patch_stride: 컨텍스트 창에서 패치를 추출할 때 사용되는 보폭입니다.\n",
    "- d_model: 모델의 숨겨진 피처 차원입니다.\n",
    "- num_layers: 모델 레이어 수입니다.\n",
    "- dropout: 인코더에서 FC 레이어에 대한 드롭아웃 확률.\n",
    "- head_dropout: 모델 헤드에 사용되는 드롭아웃 확률.\n",
    "- mode: 패치TS믹서 작동 모드. \"common_channel\"/\"mix_channel\". 공통 채널은 채널 독립 모드에서 작동합니다. 사전 훈련의 경우 \"common_channel\"을 사용합니다.\n",
    "- scaling: 윈도우별 표준 스케일링. 권장 값: \"std\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_length = 8\n",
    "config = PatchTSMixerConfig(\n",
    "    context_length=context_length,\n",
    "    prediction_length=forecast_horizon,\n",
    "    patch_length=patch_length,\n",
    "    num_input_channels=len(forecast_columns),\n",
    "    patch_stride=patch_length,\n",
    "    d_model=16,\n",
    "    num_layers=8,\n",
    "    expansion_factor=2,\n",
    "    dropout=0.1, # 0.2\n",
    "    head_dropout=0.1, # 0.2\n",
    "    mode=\"mix_channel\",\n",
    "    scaling=None,\n",
    ")\n",
    "model = PatchTSMixerForPrediction(config).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint/patchtsmixer/financial/pretrain/output/\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.001,\n",
    "    num_train_epochs=1,  # 빠르게 테스트하려면 1로 설정하세요.\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    dataloader_num_workers=num_workers,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    logging_dir=\"./checkpoint/patchtsmixer/financial/pretrain/logs/\",  # 로깅 디렉터리를 지정\n",
    "    load_best_model_at_end=True,  # 최적 모델 로드\n",
    "    metric_for_best_model=\"eval_loss\",  # 중단을 모니터링하는 메트릭\n",
    "    greater_is_better=False,  # For loss\n",
    "    label_names=[\"future_values\"],\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# 조기 종료 콜백 함수\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=10,  # Validation loss가 10번의 epoch 동안 향상되지 않으면 중단\n",
    "    early_stopping_threshold=0.0001,  # loss 변화량의 최소값\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    ")\n",
    "\n",
    "# pretrain\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6141/6141 [00:41<00:00, 149.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result:\n",
      "{'eval_loss': nan, 'eval_runtime': 58.676, 'eval_samples_per_second': 209.302, 'eval_steps_per_second': 104.66, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(\"Test result:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"patchtsmixer/financial/model/pretrain/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "trainer.save_model(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
