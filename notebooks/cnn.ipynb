{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://076923.github.io/posts/Python-pytorch-13/  \n",
    "https://sanghyu.tistory.com/24  \n",
    "https://journal-home.s3.ap-northeast-2.amazonaws.com/site/2020kics/presentation/0565.pdf  \n",
    "\n",
    "https://2bman.tistory.com/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# from loader.custom_dataset import DS, collate_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### in_channels: input의 feature dimension\n",
    "- out_channels: 내가 output으로 내고싶은 dimension\n",
    "- kernel_size: time step을 얼마만큼 볼 것인가(=frame size = filter size)\n",
    "- stride: kernel을 얼마만큼씩 이동하면서 적용할 것인가 (Default: 1)\n",
    "- dilation: kernel 내부에서 얼마만큼 띄어서 kernel을 적용할 것인가 (Default: 1)\n",
    "- padding: 한 쪽 방향으로 얼마만큼 padding할 것인가 (그 만큼 양방향으로 적용) (Default: 0)\n",
    "- groups: kernel의 height를 조절 (Default: 1)\n",
    "- bias: bias term을 둘 것인가 안둘 것인가 (Default: True)\n",
    "- padding_mode: 'zeros', 'reflect', 'reflect', 'replicate', 'circular' (Default: 'zeros')  \n",
    "  \n",
    "- Input : [Batch_size, Feature_dimension, Time_step]\n",
    "- Out : [Batch size, Feature dimension(Channel_dimension), kernel로 변경된 Time_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from loader.custom_dataset import FinDataset, FinCollate\n",
    "from model.model import FinCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Fin/Finance/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "num_classes= 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FinCNN(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_set, valid_set = train_test_split(sorted(glob(os.path.join(os.path.abspath(os.path.pardir), \"data\", \"raw\", \"*.parquet\"))),shuffle=True, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = enumerate(tqdm(DataLoader(FinDataset(data_paths=train_set), batch_size=BATCH_SIZE, collate_fn=FinCollate())))\n",
    "valid_loader = enumerate(tqdm(DataLoader(FinDataset(data_paths=valid_set), batch_size=BATCH_SIZE, collate_fn=FinCollate())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(logit, target, batch_size):\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    ## training step\n",
    "    for i, (x, y) in train_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += metric(logits, y, BATCH_SIZE)\n",
    "    \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0.0000,     0.0000,     2.1594,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    3.3632,     3.3632,     3.4084,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    3.0000,     3.0000,     3.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000]],\n",
      "\n",
      "        [[    2.7579,     1.7587,     1.1750,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    4.0224,     3.9841,     3.9617,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    5.0000,     5.0000,     5.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000]],\n",
      "\n",
      "        [[    0.0000,     3.2224,     0.0000,  ...,     1.3226,\n",
      "              1.3226,     1.7462],\n",
      "         [    3.8259,     3.9390,     3.8259,  ...,     3.8720,\n",
      "              3.8720,     3.8869],\n",
      "         [    1.0000,     5.0000,     1.0000,  ...,     5.0000,\n",
      "              1.0000,     5.0000]],\n",
      "\n",
      "        [[    0.0000,     0.6309,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    3.5313,     3.5474,     3.5313,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    1.0000,     5.0000,     1.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%( test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test(sorted(glob(os.path.join(os.path.abspath(os.path.pardir), \"data\", \"raw\", \"*.parquet\")))[0]):\n",
    "    print(y)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
