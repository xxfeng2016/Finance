{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://076923.github.io/posts/Python-pytorch-13/  \n",
    "https://sanghyu.tistory.com/24  \n",
    "https://journal-home.s3.ap-northeast-2.amazonaws.com/site/2020kics/presentation/0565.pdf  \n",
    "\n",
    "https://2bman.tistory.com/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# from torch.utils.data import DataLoader\n",
    "# from loader.custom_dataset import DS, collate_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### in_channels: input의 feature dimension\n",
    "- out_channels: 내가 output으로 내고싶은 dimension\n",
    "- kernel_size: time step을 얼마만큼 볼 것인가(=frame size = filter size)\n",
    "- stride: kernel을 얼마만큼씩 이동하면서 적용할 것인가 (Default: 1)\n",
    "- dilation: kernel 내부에서 얼마만큼 띄어서 kernel을 적용할 것인가 (Default: 1)\n",
    "- padding: 한 쪽 방향으로 얼마만큼 padding할 것인가 (그 만큼 양방향으로 적용) (Default: 0)\n",
    "- groups: kernel의 height를 조절 (Default: 1)\n",
    "- bias: bias term을 둘 것인가 안둘 것인가 (Default: True)\n",
    "- padding_mode: 'zeros', 'reflect', 'reflect', 'replicate', 'circular' (Default: 'zeros')  \n",
    "  \n",
    "- Input : [Batch_size, Feature_dimension, Time_step]\n",
    "- Out : [Batch size, Feature dimension(Channel_dimension), kernel로 변경된 Time_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data:   0%|          | 0/5992521 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from loader.custom_dataset import FinDataset, collate_func\n",
    "from model.model import FinCNN\n",
    "\n",
    "dataset = FinDataset(data_paths=sorted(glob(os.path.join(os.path.abspath(os.path.pardir), \"data\", \"raw\", \"*.parquet\"))))\n",
    "\n",
    "progress = tqdm(DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=collate_func(True)), desc=\"Loading Data\")\n",
    "\n",
    "# for idx, inv_lambda, x, y in progress:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "conv = nn.Conv1d(in_channels=3, out_channels=2, kernel_size=1, padding=(1,), padding_mode=\"zeros\")\n",
    "conv(torch.tensor(np.ones((2, 3, 10)), dtype=torch.float32, requires_grad=False))\n",
    "\n",
    "out = nn.Sigmoid()\n",
    "y = out(conv(torch.tensor(np.ones((2, 3, 3)), dtype=torch.float32, requires_grad=False)))\n",
    "torch.argmax(y, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.model' from '/home/ubuntu/Fin/Finance/model/model.py'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model.model as arc\n",
    "\n",
    "arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0931, 0.3990, 0.5079],\n",
       "        [0.3536, 0.2547, 0.3917]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output, dim=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "def featuring_x(x):\n",
    "    if len(x) < 2:\n",
    "        return np.column_stack([[0.], [0.], [0.], x[\"CCLD_DVSN\"].values]).astype(np.float16)\n",
    "    \n",
    "    volume = stats.boxcox(x[\"CNTG_VOL\"].values + 1e-9)\n",
    "    amount = stats.boxcox((x[\"STCK_PRPR\"].values * x[\"CNTG_VOL\"].values) + 1e-9)\n",
    "    trade_type = x[\"CCLD_DVSN\"].values\n",
    "\n",
    "    fx = np.column_stack([volume[0], amount[0], trade_type]) #stats.boxcox(t_diffs)[0]])\n",
    "    inv_lambda = [volume[1], amount[1]]\n",
    "    # rob_x = scaler.fit_transform(np.column_stack([volume, amount])) # t_diffs]))\n",
    "    # pt = power_transform(np.column_stack([volume, amount, t_diffs]), method=\"\")\n",
    "\n",
    "    return fx, inv_lambda # np.column_stack([t_diffs, volume, amount, trade_type])\n",
    "\n",
    "def calculate_prob_distribution(x, y):\n",
    "    if any(((y[\"STCK_PRPR\"] - x.iloc[-1][\"STCK_PRPR\"]) / x.iloc[-1][\"STCK_PRPR\"] >= 0.01).values) == True:\n",
    "        return np.array([1], dtype=np.float16)\n",
    "    else:\n",
    "        return np.array([0], dtype=np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "\n",
    "class test(Dataset):\n",
    "    def __init__(self, data_path, window_size=(3, 0), sliding_size=(0, 30), target_size=(1, 0)):\n",
    "        self.data_path = data_path\n",
    "        self.df = pd.read_parquet(self.data_path)\n",
    "        \n",
    "        self.window_size = pd.Timedelta(minutes=window_size[0], seconds=window_size[1])\n",
    "        self.sliding_size = pd.Timedelta(minutes=sliding_size[0], seconds=sliding_size[1])\n",
    "        self.target_size = pd.Timedelta(minutes=target_size[0], seconds=target_size[1])\n",
    "        \n",
    "        self.date_list = self.df['STCK_CNTG_HOUR'].dt.date.unique()\n",
    "        \n",
    "        # 다음 슬라이딩 시작 시간으로 업데이트\n",
    "        self.start_time = self.df['STCK_CNTG_HOUR'].iloc[0]\n",
    "        # 다음 슬라이딩 윈도우의 시작 인덱스 업데이트\n",
    "        self.start_idx = self.df.index[self.df['STCK_CNTG_HOUR'] >= self.start_time].min()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.start_time.time() < time(9, 0, 0):\n",
    "            end_time = datetime.combine(self.start_time.date(), time(9, 0, 0))\n",
    "\n",
    "            x = self.df[(self.df['STCK_CNTG_HOUR'] >= self.start_time) & (self.df['STCK_CNTG_HOUR'] < end_time)]\n",
    "            y = self.df[(self.df['STCK_CNTG_HOUR'] >= end_time) & (self.df[\"STCK_CNTG_HOUR\"] <= end_time + self.target_size)]\n",
    "\n",
    "            # 다음 슬라이딩 시작 시간으로 업데이트\n",
    "            self.start_time = end_time\n",
    "            # 다음 슬라이딩 윈도우의 시작 인덱스 업데이트\n",
    "            self.start_idx = self.df.index[self.df['STCK_CNTG_HOUR'] >= self.start_time].min()\n",
    "\n",
    "        elif self.start_time >= datetime.combine(self.start_time.date(), time(15, 20, 0)) - self.target_size: # \n",
    "            try:\n",
    "                end_time = datetime.combine(self.date_list[np.where(self.date_list > self.start_time.date())][0], time(9, 0, 0))\n",
    "            except IndexError:\n",
    "                self.idx += len(self.df[(self.df['STCK_CNTG_HOUR'] >= self.start_time)])\n",
    "\n",
    "                self.reset()\n",
    "                return self.__getitem__(idx)\n",
    "\n",
    "            except StopIteration:\n",
    "                raise StopIteration\n",
    "\n",
    "            x = self.df[(self.df['STCK_CNTG_HOUR'] >= self.start_time) & (self.df['STCK_CNTG_HOUR'] < end_time)]\n",
    "            y = self.df[(self.df['STCK_CNTG_HOUR'] >= end_time) & (self.df[\"STCK_CNTG_HOUR\"] <= end_time + self.target_size)]\n",
    "\n",
    "            # 다음 슬라이딩 시작 시간으로 업데이트\n",
    "            self.start_time = end_time\n",
    "            # 다음 슬라이딩 윈도우의 시작 인덱스 업데이트\n",
    "            self.start_idx = self.df.index[self.df['STCK_CNTG_HOUR'] >= self.start_time].min()\n",
    "\n",
    "        else:\n",
    "            end_time = self.start_time + self.window_size\n",
    "            x = self.df[(self.df['STCK_CNTG_HOUR'] >= self.start_time) & (self.df['STCK_CNTG_HOUR'] < end_time)]\n",
    "            y = self.df[(self.df['STCK_CNTG_HOUR'] >= end_time) & (self.df['STCK_CNTG_HOUR'] <= end_time + self.target_size)]\n",
    "\n",
    "            # 다음 슬라이딩 시작 시간으로 업데이트\n",
    "            self.start_time += self.sliding_size\n",
    "            # 다음 슬라이딩 윈도우의 시작 인덱스 업데이트\n",
    "            self.start_idx = self.df.index[self.df['STCK_CNTG_HOUR'] >= self.start_time].min()\n",
    "\n",
    "        if x.empty:\n",
    "            return self.__getitem__(idx)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class main_test(Dataset):\n",
    "    def __init__():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test(sorted(glob(os.path.join(os.path.abspath(os.path.pardir), \"data\", \"raw\", \"*.parquet\")))[0]):\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import BaseModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class FinCNN(BaseModel):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FinCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1e-9),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1e-9),\n",
    "                nn.AdaptiveAvgPool1d(1),  # Global Average Pooling\n",
    "                nn.Flatten()\n",
    "            )\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 128)  # GAP으로 인해 Linear의 input dimention == conv2의 out_channels\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (b_lambda, x, y) \u001b[38;5;129;01min\u001b[39;00m progress:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for batch_idx, (b_lambda, x, y) in progress:\n",
    "    print(x)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
